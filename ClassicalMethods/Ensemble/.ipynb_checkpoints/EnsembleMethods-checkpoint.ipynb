{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind = 'train'):\n",
    "    #Load MNIST data from 'path'\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    \n",
    "    #The with statement gurantees that the file will be closed no matter how the nested block exits\n",
    "    #Open arguments: 'rb' -> r=reading b=binary file mode\n",
    "    #Refer to the opened file as libpath\n",
    "    with open(labels_path, 'rb') as libpath:\n",
    "        #(>) big-endian and II refers to 2 usigned integers of 4 bytes each\n",
    "        #we read in 8 bytes and stores them as the magic number and the number of items\n",
    "        #See the MNIST website for the data description\n",
    "        magic, n = struct.unpack('>II',libpath.read(8))\n",
    "        #fromfile is a function in the numpy package\n",
    "        #A highly efficient way of reading binary data with a known data-type, \n",
    "        #as well as parsing simply formatted text files. \n",
    "        #Since count was not supplied it will read in all values\n",
    "        labels = np.fromfile(libpath, dtype = np.uint8)\n",
    "        #similar but reading in 4 unsigned integers to start\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
    "        #the reshape option transforms the array into the correct type of matrix\n",
    "        #nx784-- note the tru data is a 28x28 image\n",
    "        images = np.fromfile(imgpath, dtype = np.uint8).reshape(num,rows*cols)\n",
    "    print('Observations labels: %d, Observations Images: %d' % (n,num))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mnist(images,labels,seed = 123):\n",
    "    obs= np.arange(10)\n",
    "    fig,ax = plt.subplots(nrows = 2, ncols = 5,sharex = True, sharey = True)\n",
    "    ax = ax.flatten()\n",
    "    for i in obs:\n",
    "        imgs = images[labels == i,:]\n",
    "        n = imgs.shape[0]\n",
    "        index = np.random.choice(np.arange(n),size=1,replace = False)\n",
    "        img = imgs[index,:].reshape(28,28)\n",
    "        xlabel = \"{}\".format(labels_dict[i])\n",
    "        ax[i].imshow(img, cmap = 'Greys')   \n",
    "        ax[i].set_xlabel(xlabel)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_error(images, labels_true, labels_pred):\n",
    "    fig, axes = plt.subplots(3, 2)\n",
    "    p = np.not_equal(labels_true,labels_pred)\n",
    "    err = p[p==True].shape[0]/p.shape[0]\n",
    "    acc = 1 - err\n",
    "    print(\"Total miss-classified: {} out of: {}\\nMiss-classification error: {:0.2f}%\\nAccuracy :{:0.2f}%\".format(p[p==True].shape[0],p.shape[0],100*err,100*acc))\n",
    "    images = images[p,:]\n",
    "    labels_true = labels_true[p]\n",
    "    labels_pred = labels_pred[p]\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i< p[p==True].shape[0]:\n",
    "            ax.imshow(images[i].reshape((28,28)), cmap='gray')\n",
    "            xlabel = \"(True: {0}, Predicted: {1})\".format(labels_dict[labels_true[i]], labels_dict[labels_pred[i]])\n",
    "\n",
    "            ax.set_xlabel(xlabel)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ConfusionMatrix):\n",
    "    CF = np.copy(ConfusionMatrix.as_matrix())\n",
    "    TP = np.sum(np.diagonal(CF))\n",
    "    np.fill_diagonal(CF,0)\n",
    "    FP =np.sum(CF)\n",
    "    return TP/(TP+FP)   \n",
    "\n",
    "#Precision measures the accuracy of the positive predictions\n",
    "def Precision(ConfusionMatrix):\n",
    "    CF = np.copy(ConfusionMatrix.as_matrix())\n",
    "    TP = np.diagonal(ConfusionMatrix)\n",
    "    np.fill_diagonal(CF,0)\n",
    "    FP =np.sum(CF,axis=0)\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "#Recall(sensitivity, True Positive Rate)\n",
    "def Recall(ConfusionMatrix):\n",
    "    CF = np.copy(ConfusionMatrix.as_matrix())\n",
    "    TP = np.diagonal(ConfusionMatrix)\n",
    "    np.fill_diagonal(CF,0)\n",
    "    FN =np.sum(CF,axis=1)\n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def F1_Score(ConfusionMatrix):\n",
    "    precision = Precision(ConfusionMatrix)\n",
    "    recall = Recall(ConfusionMatrix)\n",
    "    F1 = 2*(precision*recall)/(precision+recall)\n",
    "    return F1\n",
    "\n",
    "def confusionMatrix(pred_labels,actual_labels,label_dict):\n",
    "    labels = [labels_dict[i] for i in label_dict.keys()]\n",
    "    M = actual_labels.shape[0]\n",
    "    tmp = np.array([np.arange(M,dtype =np.int32)+1,pred_labels,actual_labels]).T\n",
    "    result = pd.DataFrame(data = tmp, columns=['ImageId', 'Predicted_Label','Actual_Label'])\n",
    "    n = 10\n",
    "    conf = np.zeros([n,n],dtype = np.int32)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            conf[i,j] = np.sum(result[result[\"Actual_Label\"] == i][\"Predicted_Label\"] == j)\n",
    "    confusion = pd.DataFrame(conf,index=labels,columns=labels)\n",
    "    pd.Series.__unicode__ = pd.Series.to_string\n",
    "    err = np.sum(confusion.T)-np.diag(confusion)\n",
    "    precision = pd.DataFrame(Precision(confusion), columns=['Precision'],index=labels)\n",
    "    recall = pd.DataFrame(Recall(confusion), columns=['Recall'],index=labels)\n",
    "    F1 = pd.DataFrame(F1_Score(confusion), columns=['F1'],index=labels)\n",
    "    confusion = pd.concat([confusion,precision,recall,F1],axis=1)\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loc = \"../Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations labels: 60000, Observations Images: 60000\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = load_mnist(mnist_loc,kind = \"train\")\n",
    "shuffle_ind = np.random.permutation(X_train.shape[0])\n",
    "X_train, Y_train = X_train[shuffle_ind,:], Y_train[shuffle_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations labels: 10000, Observations Images: 10000\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = load_mnist(mnist_loc,kind = \"t10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0:'Zero'\n",
    ",1:'One'\n",
    ",2:'Two'\n",
    ",3:'Three'\n",
    ",4:'Four'\n",
    ",5:'Five'\n",
    ",6:'Six'\n",
    ",7:'Seven'\n",
    ",8:'Eight'\n",
    ",9:'Nine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20413082898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_mnist(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged estimator using decision trees\n",
    "\n",
    "First fit a standard decision tree of may_depth 8\n",
    "\n",
    "Then compare a bagged estimator of $B=25$ decision trees of the same depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 82.63%\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 8, random_state =123)\n",
    "tree.fit(X_train,Y_train)\n",
    "pred = tree.predict(X_train)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_train)/Y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 81.80%\n"
     ]
    }
   ],
   "source": [
    "pred = tree.predict(X_test)\n",
    "dt_pred = pred\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_index(n):\n",
    "    index = np.random.choice(n,size = n,replace = True)\n",
    "    return index\n",
    "def complement_index(n,index):\n",
    "    comp = list(set(range(n))-set(index))\n",
    "    return comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tree: 1\n",
      "Training Accuracy: 82.41%\n",
      "Testing Accuracy: 81.56%\n",
      "Fitting tree: 2\n",
      "Training Accuracy: 82.42%\n",
      "Testing Accuracy: 81.97%\n",
      "Fitting tree: 3\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 81.95%\n",
      "Fitting tree: 4\n",
      "Training Accuracy: 82.53%\n",
      "Testing Accuracy: 81.84%\n",
      "Fitting tree: 5\n",
      "Training Accuracy: 82.27%\n",
      "Testing Accuracy: 81.37%\n",
      "Fitting tree: 6\n",
      "Training Accuracy: 81.42%\n",
      "Testing Accuracy: 80.11%\n",
      "Fitting tree: 7\n",
      "Training Accuracy: 82.80%\n",
      "Testing Accuracy: 82.09%\n",
      "Fitting tree: 8\n",
      "Training Accuracy: 82.55%\n",
      "Testing Accuracy: 82.12%\n",
      "Fitting tree: 9\n",
      "Training Accuracy: 82.66%\n",
      "Testing Accuracy: 81.82%\n",
      "Fitting tree: 10\n",
      "Training Accuracy: 82.87%\n",
      "Testing Accuracy: 81.97%\n",
      "Fitting tree: 11\n",
      "Training Accuracy: 82.28%\n",
      "Testing Accuracy: 81.39%\n",
      "Fitting tree: 12\n",
      "Training Accuracy: 82.69%\n",
      "Testing Accuracy: 81.90%\n",
      "Fitting tree: 13\n",
      "Training Accuracy: 82.65%\n",
      "Testing Accuracy: 81.77%\n",
      "Fitting tree: 14\n",
      "Training Accuracy: 82.53%\n",
      "Testing Accuracy: 81.22%\n",
      "Fitting tree: 15\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 81.93%\n",
      "Fitting tree: 16\n",
      "Training Accuracy: 82.22%\n",
      "Testing Accuracy: 81.84%\n",
      "Fitting tree: 17\n",
      "Training Accuracy: 82.63%\n",
      "Testing Accuracy: 82.04%\n",
      "Fitting tree: 18\n",
      "Training Accuracy: 82.45%\n",
      "Testing Accuracy: 81.56%\n",
      "Fitting tree: 19\n",
      "Training Accuracy: 82.53%\n",
      "Testing Accuracy: 82.58%\n",
      "Fitting tree: 20\n",
      "Training Accuracy: 82.24%\n",
      "Testing Accuracy: 81.30%\n",
      "Fitting tree: 21\n",
      "Training Accuracy: 82.01%\n",
      "Testing Accuracy: 81.50%\n",
      "Fitting tree: 22\n",
      "Training Accuracy: 82.41%\n",
      "Testing Accuracy: 81.50%\n",
      "Fitting tree: 23\n",
      "Training Accuracy: 82.48%\n",
      "Testing Accuracy: 82.02%\n",
      "Fitting tree: 24\n",
      "Training Accuracy: 82.77%\n",
      "Testing Accuracy: 82.05%\n",
      "Fitting tree: 25\n",
      "Training Accuracy: 82.60%\n",
      "Testing Accuracy: 82.67%\n",
      "Fitting tree: 26\n",
      "Training Accuracy: 83.09%\n",
      "Testing Accuracy: 83.01%\n",
      "Fitting tree: 27\n",
      "Training Accuracy: 81.40%\n",
      "Testing Accuracy: 80.44%\n",
      "Fitting tree: 28\n",
      "Training Accuracy: 82.00%\n",
      "Testing Accuracy: 81.32%\n",
      "Fitting tree: 29\n",
      "Training Accuracy: 81.53%\n",
      "Testing Accuracy: 80.02%\n",
      "Fitting tree: 30\n",
      "Training Accuracy: 82.11%\n",
      "Testing Accuracy: 81.51%\n",
      "Fitting tree: 31\n",
      "Training Accuracy: 82.02%\n",
      "Testing Accuracy: 81.64%\n",
      "Fitting tree: 32\n",
      "Training Accuracy: 82.48%\n",
      "Testing Accuracy: 81.95%\n",
      "Fitting tree: 33\n",
      "Training Accuracy: 81.47%\n",
      "Testing Accuracy: 80.05%\n",
      "Fitting tree: 34\n",
      "Training Accuracy: 81.85%\n",
      "Testing Accuracy: 80.66%\n",
      "Fitting tree: 35\n",
      "Training Accuracy: 82.43%\n",
      "Testing Accuracy: 82.39%\n",
      "Fitting tree: 36\n",
      "Training Accuracy: 82.42%\n",
      "Testing Accuracy: 82.00%\n",
      "Fitting tree: 37\n",
      "Training Accuracy: 82.31%\n",
      "Testing Accuracy: 80.69%\n",
      "Fitting tree: 38\n",
      "Training Accuracy: 82.88%\n",
      "Testing Accuracy: 82.09%\n",
      "Fitting tree: 39\n",
      "Training Accuracy: 82.49%\n",
      "Testing Accuracy: 81.26%\n",
      "Fitting tree: 40\n",
      "Training Accuracy: 82.20%\n",
      "Testing Accuracy: 81.26%\n",
      "Fitting tree: 41\n",
      "Training Accuracy: 82.48%\n",
      "Testing Accuracy: 81.96%\n",
      "Fitting tree: 42\n",
      "Training Accuracy: 82.36%\n",
      "Testing Accuracy: 81.72%\n",
      "Fitting tree: 43\n",
      "Training Accuracy: 82.56%\n",
      "Testing Accuracy: 81.54%\n",
      "Fitting tree: 44\n",
      "Training Accuracy: 82.46%\n",
      "Testing Accuracy: 81.83%\n",
      "Fitting tree: 45\n",
      "Training Accuracy: 82.25%\n",
      "Testing Accuracy: 81.13%\n",
      "Fitting tree: 46\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 81.83%\n",
      "Fitting tree: 47\n",
      "Training Accuracy: 82.31%\n",
      "Testing Accuracy: 81.64%\n",
      "Fitting tree: 48\n",
      "Training Accuracy: 81.52%\n",
      "Testing Accuracy: 80.69%\n",
      "Fitting tree: 49\n",
      "Training Accuracy: 82.23%\n",
      "Testing Accuracy: 81.81%\n",
      "Fitting tree: 50\n",
      "Training Accuracy: 83.66%\n",
      "Testing Accuracy: 82.78%\n",
      "Fitting tree: 51\n",
      "Training Accuracy: 82.77%\n",
      "Testing Accuracy: 81.81%\n",
      "Fitting tree: 52\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 82.41%\n",
      "Fitting tree: 53\n",
      "Training Accuracy: 82.48%\n",
      "Testing Accuracy: 81.70%\n",
      "Fitting tree: 54\n",
      "Training Accuracy: 82.04%\n",
      "Testing Accuracy: 81.15%\n",
      "Fitting tree: 55\n",
      "Training Accuracy: 82.38%\n",
      "Testing Accuracy: 81.67%\n",
      "Fitting tree: 56\n",
      "Training Accuracy: 82.09%\n",
      "Testing Accuracy: 81.62%\n",
      "Fitting tree: 57\n",
      "Training Accuracy: 82.33%\n",
      "Testing Accuracy: 81.62%\n",
      "Fitting tree: 58\n",
      "Training Accuracy: 82.34%\n",
      "Testing Accuracy: 81.42%\n",
      "Fitting tree: 59\n",
      "Training Accuracy: 82.42%\n",
      "Testing Accuracy: 81.52%\n",
      "Fitting tree: 60\n",
      "Training Accuracy: 82.64%\n",
      "Testing Accuracy: 81.73%\n",
      "Fitting tree: 61\n",
      "Training Accuracy: 82.39%\n",
      "Testing Accuracy: 81.52%\n",
      "Fitting tree: 62\n",
      "Training Accuracy: 83.03%\n",
      "Testing Accuracy: 82.61%\n",
      "Fitting tree: 63\n",
      "Training Accuracy: 82.25%\n",
      "Testing Accuracy: 81.56%\n",
      "Fitting tree: 64\n",
      "Training Accuracy: 82.24%\n",
      "Testing Accuracy: 81.53%\n",
      "Fitting tree: 65\n",
      "Training Accuracy: 82.44%\n",
      "Testing Accuracy: 82.24%\n",
      "Fitting tree: 66\n",
      "Training Accuracy: 82.02%\n",
      "Testing Accuracy: 80.95%\n",
      "Fitting tree: 67\n",
      "Training Accuracy: 82.57%\n",
      "Testing Accuracy: 81.85%\n",
      "Fitting tree: 68\n",
      "Training Accuracy: 82.46%\n",
      "Testing Accuracy: 82.11%\n",
      "Fitting tree: 69\n",
      "Training Accuracy: 82.54%\n",
      "Testing Accuracy: 81.35%\n",
      "Fitting tree: 70\n",
      "Training Accuracy: 82.27%\n",
      "Testing Accuracy: 81.80%\n",
      "Fitting tree: 71\n",
      "Training Accuracy: 81.38%\n",
      "Testing Accuracy: 81.15%\n",
      "Fitting tree: 72\n",
      "Training Accuracy: 82.69%\n",
      "Testing Accuracy: 82.29%\n",
      "Fitting tree: 73\n",
      "Training Accuracy: 82.79%\n",
      "Testing Accuracy: 82.03%\n",
      "Fitting tree: 74\n",
      "Training Accuracy: 81.84%\n",
      "Testing Accuracy: 81.13%\n",
      "Fitting tree: 75\n",
      "Training Accuracy: 81.94%\n",
      "Testing Accuracy: 81.27%\n",
      "Fitting tree: 76\n",
      "Training Accuracy: 81.58%\n",
      "Testing Accuracy: 80.67%\n",
      "Fitting tree: 77\n",
      "Training Accuracy: 82.58%\n",
      "Testing Accuracy: 81.38%\n",
      "Fitting tree: 78\n",
      "Training Accuracy: 82.30%\n",
      "Testing Accuracy: 81.84%\n",
      "Fitting tree: 79\n",
      "Training Accuracy: 82.27%\n",
      "Testing Accuracy: 81.49%\n",
      "Fitting tree: 80\n",
      "Training Accuracy: 82.50%\n",
      "Testing Accuracy: 82.17%\n",
      "Fitting tree: 81\n",
      "Training Accuracy: 82.35%\n",
      "Testing Accuracy: 81.94%\n",
      "Fitting tree: 82\n",
      "Training Accuracy: 82.18%\n",
      "Testing Accuracy: 81.62%\n",
      "Fitting tree: 83\n",
      "Training Accuracy: 82.33%\n",
      "Testing Accuracy: 82.13%\n",
      "Fitting tree: 84\n",
      "Training Accuracy: 82.67%\n",
      "Testing Accuracy: 81.93%\n",
      "Fitting tree: 85\n",
      "Training Accuracy: 82.27%\n",
      "Testing Accuracy: 81.94%\n",
      "Fitting tree: 86\n",
      "Training Accuracy: 81.65%\n",
      "Testing Accuracy: 80.46%\n",
      "Fitting tree: 87\n",
      "Training Accuracy: 82.04%\n",
      "Testing Accuracy: 81.55%\n",
      "Fitting tree: 88\n",
      "Training Accuracy: 82.13%\n",
      "Testing Accuracy: 81.54%\n",
      "Fitting tree: 89\n",
      "Training Accuracy: 82.59%\n",
      "Testing Accuracy: 82.26%\n",
      "Fitting tree: 90\n",
      "Training Accuracy: 82.45%\n",
      "Testing Accuracy: 81.39%\n",
      "Fitting tree: 91\n",
      "Training Accuracy: 81.98%\n",
      "Testing Accuracy: 81.41%\n",
      "Fitting tree: 92\n",
      "Training Accuracy: 82.87%\n",
      "Testing Accuracy: 82.12%\n",
      "Fitting tree: 93\n",
      "Training Accuracy: 82.35%\n",
      "Testing Accuracy: 81.70%\n",
      "Fitting tree: 94\n",
      "Training Accuracy: 83.25%\n",
      "Testing Accuracy: 81.99%\n",
      "Fitting tree: 95\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 81.70%\n",
      "Fitting tree: 96\n",
      "Training Accuracy: 82.80%\n",
      "Testing Accuracy: 82.53%\n",
      "Fitting tree: 97\n",
      "Training Accuracy: 81.72%\n",
      "Testing Accuracy: 81.32%\n",
      "Fitting tree: 98\n",
      "Training Accuracy: 82.23%\n",
      "Testing Accuracy: 81.76%\n",
      "Fitting tree: 99\n",
      "Training Accuracy: 81.89%\n",
      "Testing Accuracy: 80.83%\n",
      "Fitting tree: 100\n",
      "Training Accuracy: 83.20%\n",
      "Testing Accuracy: 82.36%\n"
     ]
    }
   ],
   "source": [
    "B = 100\n",
    "trees = []\n",
    "preds_train = []\n",
    "preds_test = []\n",
    "for b in range(B):\n",
    "    index = resample_index(X_train.shape[0])\n",
    "    tmp_X = X_train[index,:]\n",
    "    tmp_Y = Y_train[index]\n",
    "    print(\"Fitting tree: {}\".format(b+1))\n",
    "    tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 8, random_state =123)\n",
    "    trees.append(tree.fit(tmp_X,tmp_Y))\n",
    "    pred = tree.predict(X_train)\n",
    "    preds_train.append(pred)\n",
    "    print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_train)/Y_train.shape[0]))\n",
    "    pred = tree.predict(X_test)\n",
    "    preds_test.append(pred)\n",
    "    print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "preds_train = np.array(preds_train).T\n",
    "preds_test= np.array(preds_test).T\n",
    "\n",
    "ensemble_train,_ = stats.mode(preds_train,axis = 1)\n",
    "ensemble_train = ensemble_train.flatten()\n",
    "ensemble_test,_ = stats.mode(preds_test,axis = 1)\n",
    "ensemble_test = ensemble_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 90.09%\n",
      "Testing Accuracy: 89.22%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(ensemble_train==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(ensemble_test==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>904</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.922449</td>\n",
       "      <td>0.903548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1075</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866935</td>\n",
       "      <td>0.947137</td>\n",
       "      <td>0.905263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>819</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>0.862105</td>\n",
       "      <td>0.793605</td>\n",
       "      <td>0.826438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>771</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>0.813291</td>\n",
       "      <td>0.763366</td>\n",
       "      <td>0.787538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>772</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>0.834595</td>\n",
       "      <td>0.786151</td>\n",
       "      <td>0.809649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>682</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.695918</td>\n",
       "      <td>0.764574</td>\n",
       "      <td>0.728632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.843424</td>\n",
       "      <td>0.821974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>837</td>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>0.898069</td>\n",
       "      <td>0.814202</td>\n",
       "      <td>0.854082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>680</td>\n",
       "      <td>44</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.698152</td>\n",
       "      <td>0.744797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>832</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.824579</td>\n",
       "      <td>0.772875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    904     0    5     11     3    11   25      4      8     9   0.885406   \n",
       "One       0  1075    7     19     3    10    4      6     10     1   0.866935   \n",
       "Two      22    33  819      9    24    17   35     21     30    22   0.862105   \n",
       "Three     7    12   41    771     5    89   16     11     26    32   0.813291   \n",
       "Four      4    25    2      3   772    22   32      6     22    94   0.834595   \n",
       "Five     22    11    5     69    19   682   23     11     26    24   0.695918   \n",
       "Six      26    11   12      9    32    34  808      1     14    11   0.801587   \n",
       "Seven     2    38   32      9    11     8    3    837     13    75   0.898069   \n",
       "Eight    20    26   24     24    18    74   50     14    680    44   0.798122   \n",
       "Nine     14     9    3     24    38    33   12     21     23   832   0.727273   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.922449  0.903548  \n",
       "One    0.947137  0.905263  \n",
       "Two    0.793605  0.826438  \n",
       "Three  0.763366  0.787538  \n",
       "Four   0.786151  0.809649  \n",
       "Five   0.764574  0.728632  \n",
       "Six    0.843424  0.821974  \n",
       "Seven  0.814202  0.854082  \n",
       "Eight  0.698152  0.744797  \n",
       "Nine   0.824579  0.772875  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision tree confusion matrix\n",
    "cm = confusionMatrix(pred_labels = dt_pred ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922927</td>\n",
       "      <td>0.965306</td>\n",
       "      <td>0.943641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1101</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950777</td>\n",
       "      <td>0.970044</td>\n",
       "      <td>0.960314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>918</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.889535</td>\n",
       "      <td>0.880153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>852</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0.881075</td>\n",
       "      <td>0.843564</td>\n",
       "      <td>0.861912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>821</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "      <td>0.877137</td>\n",
       "      <td>0.836049</td>\n",
       "      <td>0.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>751</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.814534</td>\n",
       "      <td>0.841928</td>\n",
       "      <td>0.828004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.897704</td>\n",
       "      <td>0.903361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>881</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>0.933263</td>\n",
       "      <td>0.857004</td>\n",
       "      <td>0.893509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>825</td>\n",
       "      <td>30</td>\n",
       "      <td>0.869336</td>\n",
       "      <td>0.847023</td>\n",
       "      <td>0.858034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>873</td>\n",
       "      <td>0.794359</td>\n",
       "      <td>0.865213</td>\n",
       "      <td>0.828273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    946     1    3      1     3     7    7      3      7     2   0.922927   \n",
       "One       0  1101    7     12     0     2    3      4      6     0   0.950777   \n",
       "Two      12     4  918     13    19     7   10     17     19    13   0.870968   \n",
       "Three     6     1   40    852     1    57    7      9     18    19   0.881075   \n",
       "Four      2     9    4      4   821    14   11      4     25    88   0.877137   \n",
       "Five     16     9    3     44    16   751   21      9     14     9   0.814534   \n",
       "Six      23     5    6      3    15    29  860      1     16     0   0.909091   \n",
       "Seven     1    17   36      6    10     4    0    881      8    65   0.933263   \n",
       "Eight     9     6   29     16    13    19   22      5    825    30   0.869336   \n",
       "Nine     10     5    8     16    38    32    5     11     11   873   0.794359   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.965306  0.943641  \n",
       "One    0.970044  0.960314  \n",
       "Two    0.889535  0.880153  \n",
       "Three  0.843564  0.861912  \n",
       "Four   0.836049  0.856100  \n",
       "Five   0.841928  0.828004  \n",
       "Six    0.897704  0.903361  \n",
       "Seven  0.857004  0.893509  \n",
       "Eight  0.847023  0.858034  \n",
       "Nine   0.865213  0.828273  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensemble confusion matrix\n",
    "cm_ensemble = confusionMatrix(pred_labels = ensemble_test ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OOB(X,Y,trees,notused,features):\n",
    "    sample = np.random.choice(X.shape[0],size = 2000,replace = False)\n",
    "    X = X[sample,:]\n",
    "    n= X.shape[0]\n",
    "    avg_i = []\n",
    "    m = len(trees)\n",
    "    for i in range(n):\n",
    "        x = X[i,:].reshape(1,X.shape[1])\n",
    "        count = 0\n",
    "        total = 0\n",
    "        for j in range(m):\n",
    "            unused = notused[j]\n",
    "            xj = x[:,features[j]]\n",
    "            if i in unused:\n",
    "                tree = trees[j]\n",
    "                pred = tree.predict(xj)\n",
    "                if(pred == Y[i]):\n",
    "                    count = count + 1\n",
    "                total = total +1\n",
    "        if total != 0:\n",
    "            avg_i.append(count/total)\n",
    "    err = 1-np.sum(avg_i)/n\n",
    "    return(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining OOB Approximate err at itteration: 20.\n",
      "OOB Error: 10.10%\n",
      "Determining OOB Approximate err at itteration: 40.\n",
      "OOB Error: 9.50%\n",
      "Determining OOB Approximate err at itteration: 60.\n",
      "OOB Error: 10.38%\n",
      "Determining OOB Approximate err at itteration: 80.\n",
      "OOB Error: 9.85%\n"
     ]
    }
   ],
   "source": [
    "B = 100\n",
    "trees = []\n",
    "preds_train = []\n",
    "preds_test = []\n",
    "feature_index = []\n",
    "unused_index = []\n",
    "n = X_train.shape[0]\n",
    "p = X_train.shape[1]\n",
    "m = math.floor(math.sqrt(p))\n",
    "for b in range(B):\n",
    "    index = resample_index(n)\n",
    "    unused = complement_index(n,index)\n",
    "    unused_index.append(unused)\n",
    "    features = np.random.choice(p,size = m,replace = False)\n",
    "    feature_index.append(features)\n",
    "    tmp_X = X_train[index,:][:,features]\n",
    "    tmp_Y = Y_train[index]\n",
    "    tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 8, random_state =123)\n",
    "    trees.append(tree.fit(tmp_X,tmp_Y))\n",
    "    pred = tree.predict(X_train[:,features])\n",
    "    preds_train.append(pred)\n",
    "    pred = tree.predict(X_test[:,features])\n",
    "    preds_test.append(pred)\n",
    "    if b != 0 and b % 20 == 0:\n",
    "        print(\"Determining OOB Approximate err at itteration: {}.\".format(b))\n",
    "        oob = OOB(X_train,Y_train,trees,unused_index,feature_index)\n",
    "        print(\"OOB Error: {:.2f}%\".format(100*oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = np.array(preds_train).T\n",
    "ensemble_train,_ = stats.mode(preds_train,axis = 1)\n",
    "ensemble_train = ensemble_train.flatten()\n",
    "\n",
    "preds_test = np.array(preds_test).T\n",
    "ensemble_test,_ = stats.mode(preds_test,axis = 1)\n",
    "ensemble_test = ensemble_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 90.92%\n",
      "Testing Accuracy: 90.42%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(ensemble_train==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(ensemble_test==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.918582</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.947628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1122</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.889065</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>0.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>920</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.919081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>0.852093</td>\n",
       "      <td>0.906931</td>\n",
       "      <td>0.878657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>0.938845</td>\n",
       "      <td>0.844196</td>\n",
       "      <td>0.889008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>731</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.973369</td>\n",
       "      <td>0.819507</td>\n",
       "      <td>0.889836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918082</td>\n",
       "      <td>0.959290</td>\n",
       "      <td>0.938234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.925963</td>\n",
       "      <td>0.888132</td>\n",
       "      <td>0.906653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>817</td>\n",
       "      <td>25</td>\n",
       "      <td>0.909800</td>\n",
       "      <td>0.838809</td>\n",
       "      <td>0.872863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>916</td>\n",
       "      <td>0.810619</td>\n",
       "      <td>0.907830</td>\n",
       "      <td>0.856475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    959     1    1      2     0     0    7      1      7     2   0.918582   \n",
       "One       0  1122    2      2     0     0    4      0      5     0   0.889065   \n",
       "Two      18    15  920     12     9     0   10     19     26     3   0.948454   \n",
       "Three     5    16   15    916     0     4    5     14     23    12   0.852093   \n",
       "Four      0    16    3      1   829     0   19      4      3   107   0.938845   \n",
       "Five     14    16    3     72     6   731   24      3      8    15   0.973369   \n",
       "Six      12     8    1      1     6     8  919      1      2     0   0.918082   \n",
       "Seven     2    34   17      5     4     0    0    913      3    50   0.925963   \n",
       "Eight    19    19    6     52     7     7   12     10    817    25   0.909800   \n",
       "Nine     15    15    2     12    22     1    1     21      4   916   0.810619   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.978571  0.947628  \n",
       "One    0.988546  0.936170  \n",
       "Two    0.891473  0.919081  \n",
       "Three  0.906931  0.878657  \n",
       "Four   0.844196  0.889008  \n",
       "Five   0.819507  0.889836  \n",
       "Six    0.959290  0.938234  \n",
       "Seven  0.888132  0.906653  \n",
       "Eight  0.838809  0.872863  \n",
       "Nine   0.907830  0.856475  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_ensemble = confusionMatrix(pred_labels = ensemble_test ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn implementation of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 93.20%\n",
      "Testing Accuracy: 93.14%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion = 'gini',max_depth =8,max_features= m,_\n",
    "                                n_estimators = 100, random_state = 123)\n",
    "forest.fit(X_train,Y_train)\n",
    "trainForest = forest.predict(X_train)\n",
    "testForest = forest.predict(X_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(trainForest==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(testForest==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949853</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.967451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1120</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.986784</td>\n",
       "      <td>0.975185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>950</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.942460</td>\n",
       "      <td>0.920543</td>\n",
       "      <td>0.931373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>933</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.923762</td>\n",
       "      <td>0.922392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>891</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.907332</td>\n",
       "      <td>0.917611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>792</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0.954217</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.919861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.957203</td>\n",
       "      <td>0.949767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0.946138</td>\n",
       "      <td>0.905642</td>\n",
       "      <td>0.925447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>884</td>\n",
       "      <td>27</td>\n",
       "      <td>0.917012</td>\n",
       "      <td>0.907598</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>930</td>\n",
       "      <td>0.853994</td>\n",
       "      <td>0.921705</td>\n",
       "      <td>0.886559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    966     0    1      0     0     1    5      1      5     1   0.949853   \n",
       "One       0  1120    3      2     0     1    4      1      4     0   0.963855   \n",
       "Two       8     2  950     13    13     1   10     18     13     4   0.942460   \n",
       "Three     3     2   13    933     1    17    2     13     19     7   0.921027   \n",
       "Four      1     1    1      0   891     1    9      3     12    63   0.928125   \n",
       "Five     10     7    1     31    11   792   14      4      9    13   0.954217   \n",
       "Six      17     4    1      0     8     6  917      0      5     0   0.942446   \n",
       "Seven     1    13   27      4     4     1    0    931      3    44   0.946138   \n",
       "Eight     4     5    9     16     8     6   11      4    884    27   0.917012   \n",
       "Nine      7     8    2     14    24     4    1      9     10   930   0.853994   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.985714  0.967451  \n",
       "One    0.986784  0.975185  \n",
       "Two    0.920543  0.931373  \n",
       "Three  0.923762  0.922392  \n",
       "Four   0.907332  0.917611  \n",
       "Five   0.887892  0.919861  \n",
       "Six    0.957203  0.949767  \n",
       "Seven  0.905642  0.925447  \n",
       "Eight  0.907598  0.912281  \n",
       "Nine   0.921705  0.886559  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_ensemble = confusionMatrix(pred_labels = testForest ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting-- Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-296-d978e9a4fd2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#ada =  AdaBoostClassifier(base_estimator = DecisionTreeClassifier(criterion = 'gini', max_depth = 3),n_estimators = 20, random_state = 123)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mGBC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m123\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrainGBC\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtestGBC\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML-GPU\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1034\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML-GPU\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML-GPU\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 788\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML-GPU\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML-GPU\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ada =  AdaBoostClassifier(base_estimator = DecisionTreeClassifier(criterion = 'gini', max_depth = 3),n_estimators = 20, random_state = 123)\n",
    "GBC = GradientBoostingClassifier(max_depth = 3,n_estimators = 20, random_state = 123)\n",
    "GBC.fit(X_train,Y_train)\n",
    "trainGBC= GBC.predict(X_train)\n",
    "testGBC= GBC.predict(X_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(trainGBC==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(testGBC==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind = 'train'):\n",
    "    #Load MNIST data from 'path'\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    \n",
    "    #The with statement gurantees that the file will be closed no matter how the nested block exits\n",
    "    #Open arguments: 'rb' -> r=reading b=binary file mode\n",
    "    #Refer to the opened file as libpath\n",
    "    with open(labels_path, 'rb') as libpath:\n",
    "        #(>) big-endian and II refers to 2 usigned integers of 4 bytes each\n",
    "        #we read in 8 bytes and stores them as the magic number and the number of items\n",
    "        #See the MNIST website for the data description\n",
    "        magic, n = struct.unpack('>II',libpath.read(8))\n",
    "        #fromfile is a function in the numpy package\n",
    "        #A highly efficient way of reading binary data with a known data-type, \n",
    "        #as well as parsing simply formatted text files. \n",
    "        #Since count was not supplied it will read in all values\n",
    "        labels = np.fromfile(libpath, dtype = np.uint8)\n",
    "        #similar but reading in 4 unsigned integers to start\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
    "        #the reshape option transforms the array into the correct type of matrix\n",
    "        #nx784-- note the tru data is a 28x28 image\n",
    "        images = np.fromfile(imgpath, dtype = np.uint8).reshape(num,rows*cols)\n",
    "    print('Observations labels: %d, Observations Images: %d' % (n,num))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mnist(images,labels,seed = 123):\n",
    "    obs= np.arange(10)\n",
    "    fig,ax = plt.subplots(nrows = 2, ncols = 5,sharex = True, sharey = True)\n",
    "    ax = ax.flatten()\n",
    "    for i in obs:\n",
    "        imgs = images[labels == i,:]\n",
    "        n = imgs.shape[0]\n",
    "        index = np.random.choice(np.arange(n),size=1,replace = False)\n",
    "        img = imgs[index,:].reshape(28,28)\n",
    "        xlabel = \"{}\".format(labels_dict[i])\n",
    "        ax[i].imshow(img, cmap = 'Greys')   \n",
    "        ax[i].set_xlabel(xlabel)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_error(images, labels_true, labels_pred):\n",
    "    fig, axes = plt.subplots(3, 2)\n",
    "    p = np.not_equal(labels_true,labels_pred)\n",
    "    err = p[p==True].shape[0]/p.shape[0]\n",
    "    acc = 1 - err\n",
    "    print(\"Total miss-classified: {} out of: {}\\nMiss-classification error: {:0.2f}%\\nAccuracy :{:0.2f}%\".format(p[p==True].shape[0],p.shape[0],100*err,100*acc))\n",
    "    images = images[p,:]\n",
    "    labels_true = labels_true[p]\n",
    "    labels_pred = labels_pred[p]\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i< p[p==True].shape[0]:\n",
    "            ax.imshow(images[i].reshape((28,28)), cmap='gray')\n",
    "            xlabel = \"(True: {0}, Predicted: {1})\".format(labels_dict[labels_true[i]], labels_dict[labels_pred[i]])\n",
    "\n",
    "            ax.set_xlabel(xlabel)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ConfusionMatrix):\n",
    "    CF = np.copy(ConfusionMatrix.as_matrix())\n",
    "    TP = np.sum(np.diagonal(CF))\n",
    "    np.fill_diagonal(CF,0)\n",
    "    FP =np.sum(CF)\n",
    "    return TP/(TP+FP)   \n",
    "\n",
    "#Precision measures the accuracy of the positive predictions\n",
    "def Precision(ConfusionMatrix):\n",
    "    CF = np.copy(ConfusionMatrix.as_matrix())\n",
    "    TP = np.diagonal(ConfusionMatrix)\n",
    "    np.fill_diagonal(CF,0)\n",
    "    FP =np.sum(CF,axis=0)\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "#Recall(sensitivity, True Positive Rate)\n",
    "def Recall(ConfusionMatrix):\n",
    "    CF = np.copy(ConfusionMatrix.as_matrix())\n",
    "    TP = np.diagonal(ConfusionMatrix)\n",
    "    np.fill_diagonal(CF,0)\n",
    "    FN =np.sum(CF,axis=1)\n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def F1_Score(ConfusionMatrix):\n",
    "    precision = Precision(ConfusionMatrix)\n",
    "    recall = Recall(ConfusionMatrix)\n",
    "    F1 = 2*(precision*recall)/(precision+recall)\n",
    "    return F1\n",
    "\n",
    "def confusionMatrix(pred_labels,actual_labels,label_dict):\n",
    "    labels = [labels_dict[i] for i in label_dict.keys()]\n",
    "    M = actual_labels.shape[0]\n",
    "    tmp = np.array([np.arange(M,dtype =np.int32)+1,pred_labels,actual_labels]).T\n",
    "    result = pd.DataFrame(data = tmp, columns=['ImageId', 'Predicted_Label','Actual_Label'])\n",
    "    n = 10\n",
    "    conf = np.zeros([n,n],dtype = np.int32)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            conf[i,j] = np.sum(result[result[\"Actual_Label\"] == i][\"Predicted_Label\"] == j)\n",
    "    confusion = pd.DataFrame(conf,index=labels,columns=labels)\n",
    "    pd.Series.__unicode__ = pd.Series.to_string\n",
    "    err = np.sum(confusion.T)-np.diag(confusion)\n",
    "    precision = pd.DataFrame(Precision(confusion), columns=['Precision'],index=labels)\n",
    "    recall = pd.DataFrame(Recall(confusion), columns=['Recall'],index=labels)\n",
    "    F1 = pd.DataFrame(F1_Score(confusion), columns=['F1'],index=labels)\n",
    "    confusion = pd.concat([confusion,precision,recall,F1],axis=1)\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loc = \"../Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations labels: 60000, Observations Images: 60000\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = load_mnist(mnist_loc,kind = \"train\")\n",
    "shuffle_ind = np.random.permutation(X_train.shape[0])\n",
    "X_train, Y_train = X_train[shuffle_ind,:], Y_train[shuffle_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations labels: 10000, Observations Images: 10000\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = load_mnist(mnist_loc,kind = \"t10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0:'Zero'\n",
    ",1:'One'\n",
    ",2:'Two'\n",
    ",3:'Three'\n",
    ",4:'Four'\n",
    ",5:'Five'\n",
    ",6:'Six'\n",
    ",7:'Seven'\n",
    ",8:'Eight'\n",
    ",9:'Nine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQVKAEhGRIClAiYhIkBSgREQkSP8P9qar4KkN9kQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x190b2539278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_mnist(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged estimator using decision trees\n",
    "\n",
    "First fit a standard decision tree of may_depth 8\n",
    "\n",
    "Then compare a bagged estimator of $B=25$ decision trees of the same depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 82.63%\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 8, random_state =123)\n",
    "tree.fit(X_train,Y_train)\n",
    "pred = tree.predict(X_train)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_train)/Y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 81.80%\n"
     ]
    }
   ],
   "source": [
    "pred = tree.predict(X_test)\n",
    "dt_pred = pred\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_index(n):\n",
    "    index = np.random.choice(n,size = n,replace = True)\n",
    "    return index\n",
    "def complement_index(n,index):\n",
    "    comp = list(set(range(n))-set(index))\n",
    "    return comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tree: 1\n",
      "Training Accuracy: 82.37%\n",
      "Testing Accuracy: 81.82%\n",
      "Fitting tree: 2\n",
      "Training Accuracy: 82.50%\n",
      "Testing Accuracy: 81.94%\n",
      "Fitting tree: 3\n",
      "Training Accuracy: 83.36%\n",
      "Testing Accuracy: 82.03%\n",
      "Fitting tree: 4\n",
      "Training Accuracy: 82.52%\n",
      "Testing Accuracy: 81.49%\n",
      "Fitting tree: 5\n",
      "Training Accuracy: 81.86%\n",
      "Testing Accuracy: 80.87%\n",
      "Fitting tree: 6\n",
      "Training Accuracy: 82.23%\n",
      "Testing Accuracy: 81.77%\n",
      "Fitting tree: 7\n",
      "Training Accuracy: 82.49%\n",
      "Testing Accuracy: 81.25%\n",
      "Fitting tree: 8\n",
      "Training Accuracy: 82.45%\n",
      "Testing Accuracy: 82.08%\n",
      "Fitting tree: 9\n",
      "Training Accuracy: 82.64%\n",
      "Testing Accuracy: 82.62%\n",
      "Fitting tree: 10\n",
      "Training Accuracy: 82.61%\n",
      "Testing Accuracy: 81.81%\n",
      "Fitting tree: 11\n",
      "Training Accuracy: 82.23%\n",
      "Testing Accuracy: 81.50%\n",
      "Fitting tree: 12\n",
      "Training Accuracy: 82.61%\n",
      "Testing Accuracy: 82.28%\n",
      "Fitting tree: 13\n",
      "Training Accuracy: 81.37%\n",
      "Testing Accuracy: 79.82%\n",
      "Fitting tree: 14\n",
      "Training Accuracy: 82.39%\n",
      "Testing Accuracy: 81.72%\n",
      "Fitting tree: 15\n",
      "Training Accuracy: 82.11%\n",
      "Testing Accuracy: 81.09%\n",
      "Fitting tree: 16\n",
      "Training Accuracy: 82.78%\n",
      "Testing Accuracy: 81.61%\n",
      "Fitting tree: 17\n",
      "Training Accuracy: 82.38%\n",
      "Testing Accuracy: 81.81%\n",
      "Fitting tree: 18\n",
      "Training Accuracy: 82.80%\n",
      "Testing Accuracy: 82.42%\n",
      "Fitting tree: 19\n",
      "Training Accuracy: 82.22%\n",
      "Testing Accuracy: 81.34%\n",
      "Fitting tree: 20\n",
      "Training Accuracy: 82.05%\n",
      "Testing Accuracy: 80.80%\n",
      "Fitting tree: 21\n",
      "Training Accuracy: 82.70%\n",
      "Testing Accuracy: 82.28%\n",
      "Fitting tree: 22\n",
      "Training Accuracy: 82.43%\n",
      "Testing Accuracy: 81.63%\n",
      "Fitting tree: 23\n",
      "Training Accuracy: 80.84%\n",
      "Testing Accuracy: 79.59%\n",
      "Fitting tree: 24\n",
      "Training Accuracy: 82.06%\n",
      "Testing Accuracy: 81.40%\n",
      "Fitting tree: 25\n",
      "Training Accuracy: 81.77%\n",
      "Testing Accuracy: 81.27%\n",
      "Fitting tree: 26\n",
      "Training Accuracy: 82.41%\n",
      "Testing Accuracy: 81.43%\n",
      "Fitting tree: 27\n",
      "Training Accuracy: 82.82%\n",
      "Testing Accuracy: 82.12%\n",
      "Fitting tree: 28\n",
      "Training Accuracy: 82.61%\n",
      "Testing Accuracy: 81.86%\n",
      "Fitting tree: 29\n",
      "Training Accuracy: 82.45%\n",
      "Testing Accuracy: 82.10%\n",
      "Fitting tree: 30\n",
      "Training Accuracy: 82.49%\n",
      "Testing Accuracy: 81.91%\n",
      "Fitting tree: 31\n",
      "Training Accuracy: 82.01%\n",
      "Testing Accuracy: 80.93%\n",
      "Fitting tree: 32\n",
      "Training Accuracy: 81.72%\n",
      "Testing Accuracy: 80.48%\n",
      "Fitting tree: 33\n",
      "Training Accuracy: 82.44%\n",
      "Testing Accuracy: 81.74%\n",
      "Fitting tree: 34\n",
      "Training Accuracy: 82.43%\n",
      "Testing Accuracy: 81.90%\n",
      "Fitting tree: 35\n",
      "Training Accuracy: 82.35%\n",
      "Testing Accuracy: 81.35%\n",
      "Fitting tree: 36\n",
      "Training Accuracy: 82.36%\n",
      "Testing Accuracy: 81.72%\n",
      "Fitting tree: 37\n",
      "Training Accuracy: 82.51%\n",
      "Testing Accuracy: 81.99%\n",
      "Fitting tree: 38\n",
      "Training Accuracy: 82.65%\n",
      "Testing Accuracy: 81.78%\n",
      "Fitting tree: 39\n",
      "Training Accuracy: 82.74%\n",
      "Testing Accuracy: 81.84%\n",
      "Fitting tree: 40\n",
      "Training Accuracy: 82.14%\n",
      "Testing Accuracy: 81.38%\n",
      "Fitting tree: 41\n",
      "Training Accuracy: 82.33%\n",
      "Testing Accuracy: 81.68%\n",
      "Fitting tree: 42\n",
      "Training Accuracy: 82.49%\n",
      "Testing Accuracy: 81.10%\n",
      "Fitting tree: 43\n",
      "Training Accuracy: 82.45%\n",
      "Testing Accuracy: 81.91%\n",
      "Fitting tree: 44\n",
      "Training Accuracy: 82.37%\n",
      "Testing Accuracy: 81.95%\n",
      "Fitting tree: 45\n",
      "Training Accuracy: 82.19%\n",
      "Testing Accuracy: 81.88%\n",
      "Fitting tree: 46\n",
      "Training Accuracy: 82.37%\n",
      "Testing Accuracy: 82.14%\n",
      "Fitting tree: 47\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 81.58%\n",
      "Fitting tree: 48\n",
      "Training Accuracy: 82.35%\n",
      "Testing Accuracy: 81.64%\n",
      "Fitting tree: 49\n",
      "Training Accuracy: 82.04%\n",
      "Testing Accuracy: 81.42%\n",
      "Fitting tree: 50\n",
      "Training Accuracy: 81.47%\n",
      "Testing Accuracy: 80.31%\n",
      "Fitting tree: 51\n",
      "Training Accuracy: 82.45%\n",
      "Testing Accuracy: 81.69%\n",
      "Fitting tree: 52\n",
      "Training Accuracy: 81.30%\n",
      "Testing Accuracy: 80.03%\n",
      "Fitting tree: 53\n",
      "Training Accuracy: 82.35%\n",
      "Testing Accuracy: 81.29%\n",
      "Fitting tree: 54\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 82.03%\n",
      "Fitting tree: 55\n",
      "Training Accuracy: 82.33%\n",
      "Testing Accuracy: 81.30%\n",
      "Fitting tree: 56\n",
      "Training Accuracy: 82.33%\n",
      "Testing Accuracy: 82.05%\n",
      "Fitting tree: 57\n",
      "Training Accuracy: 83.25%\n",
      "Testing Accuracy: 82.65%\n",
      "Fitting tree: 58\n",
      "Training Accuracy: 82.23%\n",
      "Testing Accuracy: 81.78%\n",
      "Fitting tree: 59\n",
      "Training Accuracy: 82.60%\n",
      "Testing Accuracy: 81.42%\n",
      "Fitting tree: 60\n",
      "Training Accuracy: 82.67%\n",
      "Testing Accuracy: 81.95%\n",
      "Fitting tree: 61\n",
      "Training Accuracy: 82.71%\n",
      "Testing Accuracy: 81.89%\n",
      "Fitting tree: 62\n",
      "Training Accuracy: 82.58%\n",
      "Testing Accuracy: 82.14%\n",
      "Fitting tree: 63\n",
      "Training Accuracy: 82.89%\n",
      "Testing Accuracy: 82.29%\n",
      "Fitting tree: 64\n",
      "Training Accuracy: 82.53%\n",
      "Testing Accuracy: 81.98%\n",
      "Fitting tree: 65\n",
      "Training Accuracy: 82.84%\n",
      "Testing Accuracy: 82.12%\n",
      "Fitting tree: 66\n",
      "Training Accuracy: 82.30%\n",
      "Testing Accuracy: 81.48%\n",
      "Fitting tree: 67\n",
      "Training Accuracy: 81.54%\n",
      "Testing Accuracy: 80.31%\n",
      "Fitting tree: 68\n",
      "Training Accuracy: 82.11%\n",
      "Testing Accuracy: 81.70%\n",
      "Fitting tree: 69\n",
      "Training Accuracy: 82.19%\n",
      "Testing Accuracy: 82.16%\n",
      "Fitting tree: 70\n",
      "Training Accuracy: 81.75%\n",
      "Testing Accuracy: 81.04%\n",
      "Fitting tree: 71\n",
      "Training Accuracy: 82.83%\n",
      "Testing Accuracy: 81.98%\n",
      "Fitting tree: 72\n",
      "Training Accuracy: 82.30%\n",
      "Testing Accuracy: 81.17%\n",
      "Fitting tree: 73\n",
      "Training Accuracy: 82.66%\n",
      "Testing Accuracy: 82.06%\n",
      "Fitting tree: 74\n",
      "Training Accuracy: 82.79%\n",
      "Testing Accuracy: 82.03%\n",
      "Fitting tree: 75\n",
      "Training Accuracy: 82.47%\n",
      "Testing Accuracy: 81.74%\n",
      "Fitting tree: 76\n",
      "Training Accuracy: 82.00%\n",
      "Testing Accuracy: 80.69%\n",
      "Fitting tree: 77\n",
      "Training Accuracy: 82.16%\n",
      "Testing Accuracy: 81.43%\n",
      "Fitting tree: 78\n",
      "Training Accuracy: 82.14%\n",
      "Testing Accuracy: 81.11%\n",
      "Fitting tree: 79\n",
      "Training Accuracy: 82.74%\n",
      "Testing Accuracy: 81.90%\n",
      "Fitting tree: 80\n",
      "Training Accuracy: 82.75%\n",
      "Testing Accuracy: 81.45%\n",
      "Fitting tree: 81\n",
      "Training Accuracy: 82.39%\n",
      "Testing Accuracy: 81.49%\n",
      "Fitting tree: 82\n",
      "Training Accuracy: 82.61%\n",
      "Testing Accuracy: 81.95%\n",
      "Fitting tree: 83\n",
      "Training Accuracy: 82.08%\n",
      "Testing Accuracy: 81.38%\n",
      "Fitting tree: 84\n",
      "Training Accuracy: 82.40%\n",
      "Testing Accuracy: 81.52%\n",
      "Fitting tree: 85\n",
      "Training Accuracy: 82.84%\n",
      "Testing Accuracy: 82.09%\n",
      "Fitting tree: 86\n",
      "Training Accuracy: 82.45%\n",
      "Testing Accuracy: 82.09%\n",
      "Fitting tree: 87\n",
      "Training Accuracy: 82.52%\n",
      "Testing Accuracy: 81.51%\n",
      "Fitting tree: 88\n",
      "Training Accuracy: 81.88%\n",
      "Testing Accuracy: 81.29%\n",
      "Fitting tree: 89\n",
      "Training Accuracy: 82.24%\n",
      "Testing Accuracy: 81.51%\n",
      "Fitting tree: 90\n",
      "Training Accuracy: 82.54%\n",
      "Testing Accuracy: 82.16%\n",
      "Fitting tree: 91\n",
      "Training Accuracy: 81.79%\n",
      "Testing Accuracy: 80.60%\n",
      "Fitting tree: 92\n",
      "Training Accuracy: 82.48%\n",
      "Testing Accuracy: 82.08%\n",
      "Fitting tree: 93\n",
      "Training Accuracy: 82.33%\n",
      "Testing Accuracy: 82.14%\n",
      "Fitting tree: 94\n",
      "Training Accuracy: 82.44%\n",
      "Testing Accuracy: 81.49%\n",
      "Fitting tree: 95\n",
      "Training Accuracy: 81.91%\n",
      "Testing Accuracy: 81.74%\n",
      "Fitting tree: 96\n",
      "Training Accuracy: 82.63%\n",
      "Testing Accuracy: 82.27%\n",
      "Fitting tree: 97\n",
      "Training Accuracy: 82.32%\n",
      "Testing Accuracy: 82.09%\n",
      "Fitting tree: 98\n",
      "Training Accuracy: 82.42%\n",
      "Testing Accuracy: 81.73%\n",
      "Fitting tree: 99\n",
      "Training Accuracy: 82.32%\n",
      "Testing Accuracy: 81.55%\n",
      "Fitting tree: 100\n",
      "Training Accuracy: 82.39%\n",
      "Testing Accuracy: 81.48%\n"
     ]
    }
   ],
   "source": [
    "B = 100\n",
    "trees = []\n",
    "preds_train = []\n",
    "preds_test = []\n",
    "for b in range(B):\n",
    "    index = resample_index(X_train.shape[0])\n",
    "    tmp_X = X_train[index,:]\n",
    "    tmp_Y = Y_train[index]\n",
    "    print(\"Fitting tree: {}\".format(b+1))\n",
    "    tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 8, random_state =123)\n",
    "    trees.append(tree.fit(tmp_X,tmp_Y))\n",
    "    pred = tree.predict(X_train)\n",
    "    preds_train.append(pred)\n",
    "    print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_train)/Y_train.shape[0]))\n",
    "    pred = tree.predict(X_test)\n",
    "    preds_test.append(pred)\n",
    "    print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(pred==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "preds_train = np.array(preds_train).T\n",
    "preds_test= np.array(preds_test).T\n",
    "\n",
    "ensemble_train,_ = stats.mode(preds_train,axis = 1)\n",
    "ensemble_train = ensemble_train.flatten()\n",
    "ensemble_test,_ = stats.mode(preds_test,axis = 1)\n",
    "ensemble_test = ensemble_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 89.56%\n",
      "Testing Accuracy: 88.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(ensemble_train==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(ensemble_test==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>904</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.922449</td>\n",
       "      <td>0.903548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1075</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866935</td>\n",
       "      <td>0.947137</td>\n",
       "      <td>0.905263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>819</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>0.862105</td>\n",
       "      <td>0.793605</td>\n",
       "      <td>0.826438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>771</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>0.813291</td>\n",
       "      <td>0.763366</td>\n",
       "      <td>0.787538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>772</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>0.834595</td>\n",
       "      <td>0.786151</td>\n",
       "      <td>0.809649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>682</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.695918</td>\n",
       "      <td>0.764574</td>\n",
       "      <td>0.728632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.843424</td>\n",
       "      <td>0.821974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>837</td>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>0.898069</td>\n",
       "      <td>0.814202</td>\n",
       "      <td>0.854082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>680</td>\n",
       "      <td>44</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.698152</td>\n",
       "      <td>0.744797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>832</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.824579</td>\n",
       "      <td>0.772875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    904     0    5     11     3    11   25      4      8     9   0.885406   \n",
       "One       0  1075    7     19     3    10    4      6     10     1   0.866935   \n",
       "Two      22    33  819      9    24    17   35     21     30    22   0.862105   \n",
       "Three     7    12   41    771     5    89   16     11     26    32   0.813291   \n",
       "Four      4    25    2      3   772    22   32      6     22    94   0.834595   \n",
       "Five     22    11    5     69    19   682   23     11     26    24   0.695918   \n",
       "Six      26    11   12      9    32    34  808      1     14    11   0.801587   \n",
       "Seven     2    38   32      9    11     8    3    837     13    75   0.898069   \n",
       "Eight    20    26   24     24    18    74   50     14    680    44   0.798122   \n",
       "Nine     14     9    3     24    38    33   12     21     23   832   0.727273   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.922449  0.903548  \n",
       "One    0.947137  0.905263  \n",
       "Two    0.793605  0.826438  \n",
       "Three  0.763366  0.787538  \n",
       "Four   0.786151  0.809649  \n",
       "Five   0.764574  0.728632  \n",
       "Six    0.843424  0.821974  \n",
       "Seven  0.814202  0.854082  \n",
       "Eight  0.698152  0.744797  \n",
       "Nine   0.824579  0.772875  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision tree confusion matrix\n",
    "cm = confusionMatrix(pred_labels = dt_pred ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933860</td>\n",
       "      <td>0.965306</td>\n",
       "      <td>0.949323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1107</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955134</td>\n",
       "      <td>0.975330</td>\n",
       "      <td>0.965126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>923</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.894380</td>\n",
       "      <td>0.889210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.836634</td>\n",
       "      <td>0.862685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>823</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>95</td>\n",
       "      <td>0.884946</td>\n",
       "      <td>0.838086</td>\n",
       "      <td>0.860879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>765</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0.863431</td>\n",
       "      <td>0.857623</td>\n",
       "      <td>0.860517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.908142</td>\n",
       "      <td>0.908616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>885</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.860895</td>\n",
       "      <td>0.897111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>831</td>\n",
       "      <td>35</td>\n",
       "      <td>0.846232</td>\n",
       "      <td>0.853183</td>\n",
       "      <td>0.849693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>888</td>\n",
       "      <td>0.782379</td>\n",
       "      <td>0.880079</td>\n",
       "      <td>0.828358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    946     1    3      3     3     7    5      4      6     2   0.933860   \n",
       "One       0  1107    7      7     0     2    4      2      6     0   0.955134   \n",
       "Two      11     6  923     14    16     4   11     15     16    16   0.884100   \n",
       "Three     6     1   36    845     1    45   10     10     38    18   0.890411   \n",
       "Four      3     5    6      2   823     6   14      5     23    95   0.884946   \n",
       "Five     10     6    2     38    16   765   20      6     15    14   0.863431   \n",
       "Six      19     6    5      2    15    27  870      1     13     0   0.909091   \n",
       "Seven     1    17   29      8     8     4    0    885      9    67   0.936508   \n",
       "Eight     8     4   29     15    12    17   18      5    831    35   0.846232   \n",
       "Nine      9     6    4     15    36     9    5     12     25   888   0.782379   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.965306  0.949323  \n",
       "One    0.975330  0.965126  \n",
       "Two    0.894380  0.889210  \n",
       "Three  0.836634  0.862685  \n",
       "Four   0.838086  0.860879  \n",
       "Five   0.857623  0.860517  \n",
       "Six    0.908142  0.908616  \n",
       "Seven  0.860895  0.897111  \n",
       "Eight  0.853183  0.849693  \n",
       "Nine   0.880079  0.828358  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensemble confusion matrix\n",
    "cm_ensemble = confusionMatrix(pred_labels = ensemble_test ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OOB(X,Y,trees,notused,features):\n",
    "    sample = np.random.choice(X.shape[0],size = 2000,replace = False)\n",
    "    X = X[sample,:]\n",
    "    n= X.shape[0]\n",
    "    avg_i = []\n",
    "    m = len(trees)\n",
    "    for i in range(n):\n",
    "        x = X[i,:].reshape(1,X.shape[1])\n",
    "        count = 0\n",
    "        total = 0\n",
    "        for j in range(m):\n",
    "            unused = notused[j]\n",
    "            xj = x[:,features[j]]\n",
    "            if i in unused:\n",
    "                tree = trees[j]\n",
    "                pred = tree.predict(xj)\n",
    "                if(pred == Y[i]):\n",
    "                    count = count + 1\n",
    "                total = total +1\n",
    "        if total != 0:\n",
    "            avg_i.append(count/total)\n",
    "    err = 1-np.sum(avg_i)/n\n",
    "    return(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining OOB Approximate err at itteration: 20.\n",
      "OOB Error: 91.01%\n",
      "Determining OOB Approximate err at itteration: 40.\n",
      "OOB Error: 89.60%\n",
      "Determining OOB Approximate err at itteration: 60.\n",
      "OOB Error: 89.47%\n",
      "Determining OOB Approximate err at itteration: 80.\n",
      "OOB Error: 90.09%\n"
     ]
    }
   ],
   "source": [
    "B = 100\n",
    "trees = []\n",
    "preds_train = []\n",
    "preds_test = []\n",
    "feature_index = []\n",
    "unused_index = []\n",
    "n = X_train.shape[0]\n",
    "p = X_train.shape[1]\n",
    "m = math.floor(math.sqrt(p))\n",
    "for b in range(B):\n",
    "    index = resample_index(n)\n",
    "    unused = complement_index(n,index)\n",
    "    unused_index.append(unused)\n",
    "    features = np.random.choice(p,size = m,replace = False)\n",
    "    feature_index.append(features)\n",
    "    tmp_X = X_train[index,:][:,features]\n",
    "    tmp_Y = Y_train[index]\n",
    "    tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 8, random_state =123)\n",
    "    trees.append(tree.fit(tmp_X,tmp_Y))\n",
    "    pred = tree.predict(X_train[:,features])\n",
    "    preds_train.append(pred)\n",
    "    pred = tree.predict(X_test[:,features])\n",
    "    preds_test.append(pred)\n",
    "    if b != 0 and b % 20 == 0:\n",
    "        print(\"Determining OOB Approximate err at itteration: {}.\".format(b))\n",
    "        oob = OOB(X_train,Y_train,trees,unused_index,feature_index)\n",
    "        print(\"OOB Error: {:.2f}%\".format(100*oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = np.array(preds_train).T\n",
    "ensemble_train,_ = stats.mode(preds_train,axis = 1)\n",
    "ensemble_train = ensemble_train.flatten()\n",
    "\n",
    "preds_test = np.array(preds_test).T\n",
    "ensemble_test,_ = stats.mode(preds_test,axis = 1)\n",
    "ensemble_test = ensemble_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 91.72%\n",
      "Testing Accuracy: 91.57%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(ensemble_train==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(ensemble_test==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.973469</td>\n",
       "      <td>0.951147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.911598</td>\n",
       "      <td>0.990308</td>\n",
       "      <td>0.949324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>927</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941117</td>\n",
       "      <td>0.898256</td>\n",
       "      <td>0.919187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>930</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.861909</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.890378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.933619</td>\n",
       "      <td>0.887984</td>\n",
       "      <td>0.910230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>728</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.816143</td>\n",
       "      <td>0.886724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>930</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921705</td>\n",
       "      <td>0.970772</td>\n",
       "      <td>0.945602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>933</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.907588</td>\n",
       "      <td>0.916503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>838</td>\n",
       "      <td>18</td>\n",
       "      <td>0.907909</td>\n",
       "      <td>0.860370</td>\n",
       "      <td>0.883500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>921</td>\n",
       "      <td>0.874644</td>\n",
       "      <td>0.912785</td>\n",
       "      <td>0.893307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    954     0    0      2     0     2    9      1     11     1   0.929825   \n",
       "One       0  1124    4      2     0     0    3      0      2     0   0.911598   \n",
       "Two      16     9  927     15    11     0   11     22     19     2   0.941117   \n",
       "Three     5     8   18    930     0     5    4     12     21     7   0.861909   \n",
       "Four      0    15    4      0   872     1   18      5      3    64   0.933619   \n",
       "Five     14    12    3     73    10   728   23      4     14    11   0.970667   \n",
       "Six      11     5    1      0     6     3  930      1      1     0   0.921705   \n",
       "Seven     2    30   20      2     7     0    0    933      5    29   0.925595   \n",
       "Eight    12    18    6     46     6    10    9     11    838    18   0.907909   \n",
       "Nine     12    12    2      9    22     1    2     19      9   921   0.874644   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.973469  0.951147  \n",
       "One    0.990308  0.949324  \n",
       "Two    0.898256  0.919187  \n",
       "Three  0.920792  0.890378  \n",
       "Four   0.887984  0.910230  \n",
       "Five   0.816143  0.886724  \n",
       "Six    0.970772  0.945602  \n",
       "Seven  0.907588  0.916503  \n",
       "Eight  0.860370  0.883500  \n",
       "Nine   0.912785  0.893307  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_ensemble = confusionMatrix(pred_labels = ensemble_test ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn implementation of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 93.30%\n",
      "Testing Accuracy: 93.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion = 'gini',max_depth =8,max_features= m,n_estimators = 100, random_state = 123)\n",
    "forest.fit(X_train,Y_train)\n",
    "trainForest = forest.predict(X_train)\n",
    "testForest = forest.predict(X_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(trainForest==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(testForest==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951677</td>\n",
       "      <td>0.984694</td>\n",
       "      <td>0.967904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1119</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962995</td>\n",
       "      <td>0.985903</td>\n",
       "      <td>0.974314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>947</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.917636</td>\n",
       "      <td>0.927976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>927</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>0.917822</td>\n",
       "      <td>0.917822</td>\n",
       "      <td>0.917822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>886</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.932632</td>\n",
       "      <td>0.902240</td>\n",
       "      <td>0.917184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>792</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.916136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942740</td>\n",
       "      <td>0.962422</td>\n",
       "      <td>0.952479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>936</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.910506</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>879</td>\n",
       "      <td>27</td>\n",
       "      <td>0.911826</td>\n",
       "      <td>0.902464</td>\n",
       "      <td>0.907121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>932</td>\n",
       "      <td>0.856618</td>\n",
       "      <td>0.923687</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    965     0    0      0     0     3    5      1      5     1   0.951677   \n",
       "One       0  1119    4      3     0     1    3      1      4     0   0.962995   \n",
       "Two       8     3  947     12    13     1   12     18     13     5   0.938553   \n",
       "Three     6     0   17    927     2    17    0     14     18     9   0.917822   \n",
       "Four      3     3    2      0   886     1   11      2     10    64   0.932632   \n",
       "Five      7    11    0     32     9   792   14      4     12    11   0.946237   \n",
       "Six      13     4    0      0     8     8  922      0      3     0   0.942740   \n",
       "Seven     2    10   29      3     4     0    0    936      5    39   0.947368   \n",
       "Eight     4     5    8     20     8     9   10      4    879    27   0.911826   \n",
       "Nine      6     7    2     13    20     5    1      8     15   932   0.856618   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.984694  0.967904  \n",
       "One    0.985903  0.974314  \n",
       "Two    0.917636  0.927976  \n",
       "Three  0.917822  0.917822  \n",
       "Four   0.902240  0.917184  \n",
       "Five   0.887892  0.916136  \n",
       "Six    0.962422  0.952479  \n",
       "Seven  0.910506  0.928571  \n",
       "Eight  0.902464  0.907121  \n",
       "Nine   0.923687  0.888889  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_ensemble = confusionMatrix(pred_labels = testForest ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting-- Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 98.39%\n",
      "Testing Accuracy: 96.12%\n"
     ]
    }
   ],
   "source": [
    "#ada =  AdaBoostClassifier(base_estimator = DecisionTreeClassifier(criterion = 'gini', max_depth = 3),n_estimators = 20, random_state = 123)\n",
    "GBC = GradientBoostingClassifier(max_depth = 4,n_estimators = 100, random_state = 123)\n",
    "GBC.fit(X_train,Y_train)\n",
    "trainGBC= GBC.predict(X_train)\n",
    "testGBC= GBC.predict(X_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(100*np.sum(trainGBC==Y_train)/Y_train.shape[0]))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(100*np.sum(testGBC==Y_test)/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>Five</th>\n",
       "      <th>Six</th>\n",
       "      <th>Seven</th>\n",
       "      <th>Eight</th>\n",
       "      <th>Nine</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971859</td>\n",
       "      <td>0.986735</td>\n",
       "      <td>0.979241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One</th>\n",
       "      <td>0</td>\n",
       "      <td>1121</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980752</td>\n",
       "      <td>0.987665</td>\n",
       "      <td>0.984197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>983</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958090</td>\n",
       "      <td>0.952519</td>\n",
       "      <td>0.955296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>969</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.959406</td>\n",
       "      <td>0.954680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.963377</td>\n",
       "      <td>0.964358</td>\n",
       "      <td>0.963868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>851</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.960497</td>\n",
       "      <td>0.954036</td>\n",
       "      <td>0.957255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Six</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975789</td>\n",
       "      <td>0.967641</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>962</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.966834</td>\n",
       "      <td>0.935798</td>\n",
       "      <td>0.951063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eight</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>937</td>\n",
       "      <td>10</td>\n",
       "      <td>0.944556</td>\n",
       "      <td>0.962012</td>\n",
       "      <td>0.953204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nine</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>948</td>\n",
       "      <td>0.938614</td>\n",
       "      <td>0.939544</td>\n",
       "      <td>0.939079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zero   One  Two  Three  Four  Five  Six  Seven  Eight  Nine  Precision  \\\n",
       "Zero    967     0    0      0     0     3    4      1      4     1   0.971859   \n",
       "One       0  1121    2      1     1     1    4      0      5     0   0.980752   \n",
       "Two       5     1  983     10     8     0    2     11     11     1   0.958090   \n",
       "Three     1     0    8    969     0     7    0      9     12     4   0.950000   \n",
       "Four      1     1    5      0   947     0    3      0      3    22   0.963377   \n",
       "Five      4     2    1     12     1   851    9      3      5     4   0.960497   \n",
       "Six       6     2    1      0     5    13  927      0      4     0   0.975789   \n",
       "Seven     1     7   22      7     3     2    0    962      4    20   0.966834   \n",
       "Eight     4     1    2      8     4     5    1      2    937    10   0.944556   \n",
       "Nine      6     8    2     13    14     4    0      7      7   948   0.938614   \n",
       "\n",
       "         Recall        F1  \n",
       "Zero   0.986735  0.979241  \n",
       "One    0.987665  0.984197  \n",
       "Two    0.952519  0.955296  \n",
       "Three  0.959406  0.954680  \n",
       "Four   0.964358  0.963868  \n",
       "Five   0.954036  0.957255  \n",
       "Six    0.967641  0.971698  \n",
       "Seven  0.935798  0.951063  \n",
       "Eight  0.962012  0.953204  \n",
       "Nine   0.939544  0.939079  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_ensemble = confusionMatrix(pred_labels = testGBC ,actual_labels = Y_test,label_dict = labels_dict)\n",
    "cm_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
